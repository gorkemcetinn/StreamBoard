
# ğŸ“Š CanlÄ± KullanÄ±cÄ± Dashboard : StreamBoard

GerÃ§ek zamanlÄ± veri akÄ±ÅŸÄ±nÄ± Kafka ve Spark ile iÅŸleyip Flask Ã¼zerinden sunan, canlÄ± olarak kullanÄ±cÄ± verilerini takip edebileceÄŸiniz bir dashboard.

---

### ğŸš€ Ã–zellikler

- ğŸ¯ **GerÃ§ek ZamanlÄ± Veri Ä°ÅŸleme:** RandomUser API'den alÄ±nan veriler Kafka ile taÅŸÄ±nÄ±r, Spark ile analiz edilir.
- ğŸ“¬ **Flask REST API:** Verileri alÄ±r, saklar ve Ã¶n uca (frontend) sunar.
- ğŸ‘¥ **Dashboard ArayÃ¼zÃ¼:**
  - Son gelen kullanÄ±cÄ± bilgisi
  - Toplam kullanÄ±cÄ± sayÄ±sÄ±
  - Cinsiyet daÄŸÄ±lÄ±mÄ± (sayaÃ§ + pasta grafik)
  - CanlÄ± kullanÄ±cÄ± listesi
  - CSV dÄ±ÅŸa aktarÄ±m

---

### ğŸ§  Spark ve Kafka ile Veri AkÄ±ÅŸÄ±

Bu proje **gerÃ§ek zamanlÄ± veri iÅŸleme mimarisi** iÃ§in Kafka ve Spark'Ä± birlikte kullanÄ±r:

#### ğŸ“¦ Apache Kafka

- **Kafka**, bir mesaj kuyruÄŸu sistemidir. Bu projede RandomUser API'den Ã§ekilen veriler Kafka'ya gÃ¶nderilir.
- Ãœretilen veriler (`producer`), `"user-topic"` isimli bir topic Ã¼zerinden yayÄ±nlanÄ±r.

#### âš¡ Apache Spark Structured Streaming

- Spark, Kafka'dan gelen JSON verilerini anlÄ±k olarak iÅŸler.
- Spark ile `name.first` ve `name.last` alanlarÄ± birleÅŸtirilerek kullanÄ±cÄ± adÄ± oluÅŸturulur.
- SonuÃ§ verileri Flask API'ye gÃ¶nderilir (`POST /add_user`).

> Bu sayede arka planda akan veriler iÅŸlenip hÄ±zlÄ± bir ÅŸekilde web arayÃ¼zÃ¼ne yansÄ±tÄ±lÄ±r.

---

### ğŸ›  Gereksinimler

- Python 3.8+
- Apache Spark 3.x
- Apache Kafka
- pip paketleri:

  ```bash
  pip install flask flask-cors kafka-python requests findspark
  ```

---

### ğŸ”§ Kurulum

1. Spark ve Kafka'yÄ± baÅŸlatÄ±n.
2. Gerekli Python baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± yÃ¼kleyin.
3. AÅŸaÄŸÄ±daki dosyalar hazÄ±r olmalÄ±:
   - `main.py`
   - `app.py`
   - `randomuser_producer.py`
   - `spark_randomuser_stream.py`
   - `index.html`, `script.js`

---

### â–¶ï¸ Ã‡alÄ±ÅŸtÄ±rma

1. Docker Ã¼zerinden Kafka ve Zookeeper'Ä± baÅŸlat:
```bash
cd proje-dizini
docker-compose -f docker-compose.yaml up -d
```
| docker-compose.yaml dosyasÄ± Kafka, Zookeeper ve Kafka UI (opsiyonel) iÃ§ermelidir.

2. Ana uygulamayÄ± baÅŸlat:

```bash
python main.py
```

> Flask + Kafka Producer + Spark Streaming birlikte baÅŸlatÄ±lÄ±r.

---

### ğŸ“ API UÃ§ NoktalarÄ±

| YÃ¶ntem | URL               | AÃ§Ä±klama                 |
|--------|-------------------|--------------------------|
| GET    | `/users`          | TÃ¼m kullanÄ±cÄ±larÄ± getirir |
| GET    | `/last_user`      | Son kullanÄ±cÄ±yÄ± getirir   |
| GET    | `/stats`          | Erkek/KadÄ±n sayÄ±sÄ±nÄ± getirir |
| GET    | `/export/csv`     | CSV olarak dÄ±ÅŸa aktarÄ±r  |
| POST   | `/add_user`       | KullanÄ±cÄ± ekler (Spark tarafÄ±ndan kullanÄ±lÄ±r) |

---

### ğŸ“¸ Dashboard Ã–zeti

- Son kullanÄ±cÄ± kutusu
- Toplam kullanÄ±cÄ± sayÄ±sÄ±
- Cinsiyet daÄŸÄ±lÄ±mÄ± (sayaÃ§ + pasta grafik)
- Otomatik gÃ¼ncellenen kullanÄ±cÄ± listesi
- CSV indir butonu

---

### ğŸ“‚ Ã–rnek Ekran GÃ¶rÃ¼ntÃ¼sÃ¼



https://github.com/user-attachments/assets/03ab6ccf-662e-47bb-a8c5-65878dfcf8a6


ğŸ§© Notlar

Kafka UI arayÃ¼zÃ¼ne http://localhost:8080 adresinden eriÅŸebilirsin.

Spark, streaming query'leri terminalde gÃ¶sterebilir.
